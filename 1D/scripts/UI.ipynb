{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "716649b3-d65a-4773-a280-6a27c63f3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import importlib\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anm\n",
    "\n",
    "sys.path.insert(0, \"../src/\")\n",
    "import data\n",
    "import model\n",
    "import train\n",
    "\n",
    "import nmrglue as ng\n",
    "import scipy\n",
    "import scipy.io\n",
    "\n",
    "import gradio as gr\n",
    "import zipfile as zp\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "plt.rcParams[\"figure.max_open_warning\"] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8352e7ad-19e9-4259-9075-0649a9c31296",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c26206df-d503-4cdd-96df-f06680efbe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = \"Ensemble_PIPNet_2022_01_25_batch_6\"\n",
    "\n",
    "in_dir = f\"../data/{mod}/\"\n",
    "\n",
    "if not os.path.exists(in_dir):\n",
    "    raise ValueError(f\"Unknown model: {mod}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f2c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_split(l, delimiter):\n",
    "    \"\"\"\n",
    "    Split a line with the desired delimiter, ignoring delimiters present in arrays or strings\n",
    "    \n",
    "    Inputs: - l     Input line\n",
    "    \n",
    "    Output: - ls    List of sub-strings making up the line\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize sub-strings\n",
    "    ls = []\n",
    "    clean_l = \"\"\n",
    "    \n",
    "    # Loop over all line characters\n",
    "    in_dq = False\n",
    "    in_sq = False\n",
    "    arr_depth = 0\n",
    "    for li in l:\n",
    "        # Identify strings with double quotes\n",
    "        if li == \"\\\"\":\n",
    "            if not in_dq:\n",
    "                in_dq = True\n",
    "            else:\n",
    "                in_dq = False\n",
    "        \n",
    "        # Identify strings with single quotes\n",
    "        if li == \"\\'\":\n",
    "            if not in_sq:\n",
    "                in_sq = True\n",
    "            else:\n",
    "                in_sq = False\n",
    "        \n",
    "        # Identify arrays\n",
    "        if li == \"[\":\n",
    "            if not in_sq and not in_dq:\n",
    "                arr_depth += 1\n",
    "        if li == \"]\":\n",
    "            if not in_sq and not in_dq:\n",
    "                arr_depth -= 1\n",
    "        \n",
    "        # If the delimiter is not within quotes or in an array, split the line at that character\n",
    "        if li == delimiter and not in_dq and not in_sq and arr_depth == 0:\n",
    "            ls.append(clean_l)\n",
    "            clean_l = \"\"\n",
    "        else:\n",
    "            clean_l += li\n",
    "    \n",
    "    ls.append(clean_l)\n",
    "        \n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b681b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array(l):\n",
    "    \"\"\"\n",
    "    Get the values in an array contained in a line\n",
    "    \n",
    "    Input:  - l         Input line\n",
    "    \n",
    "    Output: - vals      Array of values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identify empty array\n",
    "    if l.strip() == \"[]\":\n",
    "        return []\n",
    "    \n",
    "    # Initialize array\n",
    "    vals = []\n",
    "    clean_l = \"\"\n",
    "    \n",
    "    # Loop over all line characters\n",
    "    arr_depth = 0\n",
    "    for li in l:\n",
    "    \n",
    "        # Identify end of array\n",
    "        if li == \"]\":\n",
    "            arr_depth -= 1\n",
    "            \n",
    "            # Check that there are not too many closing brackets for the opening ones\n",
    "            if arr_depth < 0:\n",
    "                raise ValueError(\"Missing \\\"[\\\" for matching the number of \\\"]\\\"\")\n",
    "        \n",
    "        # If we are within the array, extract the character\n",
    "        if arr_depth > 0:\n",
    "            clean_l += li\n",
    "    \n",
    "        # Identify start of array\n",
    "        if li == \"[\":\n",
    "            arr_depth += 1\n",
    "    \n",
    "    # Check that the array is properly closed at the end\n",
    "    if arr_depth > 0:\n",
    "        raise ValueError(\"Missing \\\"]\\\" for matching the number of \\\"[\\\"\")\n",
    "    \n",
    "    # Extract elements in the array\n",
    "    ls = clean_split(clean_l, \",\")\n",
    "    \n",
    "    # Get the value of each element in the array\n",
    "    for li in ls:\n",
    "        vals.append(get_val(li.strip()))\n",
    "\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62025ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val(val):\n",
    "    \n",
    "    # Remove tailing comma\n",
    "    if val.endswith(\",\"):\n",
    "        val = val[:-1]\n",
    "    \n",
    "    # Float / Int\n",
    "    if val.isnumeric():\n",
    "        \n",
    "        if \".\" in val:\n",
    "            return float(val)\n",
    "        else:\n",
    "            return int(val)\n",
    "    \n",
    "    # Bool\n",
    "    if val.lower() == \"true\":\n",
    "        return True\n",
    "    if val.lower() == \"false\":\n",
    "        return False\n",
    "    \n",
    "    # String\n",
    "    if val.startswith(\"\\\"\"):\n",
    "        return val.split(\"\\\"\")[1]\n",
    "    \n",
    "    # List\n",
    "    if val.startswith(\"[\"):\n",
    "        \n",
    "        return get_array(val)\n",
    "    \n",
    "    # Try to return a float anyway\n",
    "    return float(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "153731a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model architecture\n",
    "with open(mod + \".py\", \"r\") as F:\n",
    "    lines = F.read().split(\"\\n\")\n",
    "\n",
    "model_pars = {}\n",
    "in_pars = False\n",
    "\n",
    "# Parse script\n",
    "for l in lines:\n",
    "    \n",
    "    # Identify model parameter block start\n",
    "    if \"model_pars = \" in l:\n",
    "        in_pars = True\n",
    "    \n",
    "    # Identify model parameter block end\n",
    "    if l.strip() == \")\":\n",
    "        in_pars = False\n",
    "    \n",
    "    if in_pars:\n",
    "        # Get line\n",
    "        if \"(\" in l:\n",
    "            L = l.split(\"(\")[1].split(\"#\")[0]\n",
    "        else:\n",
    "            L = l.strip().split(\"#\")[0]\n",
    "        \n",
    "        key, val = L.split(\"=\")\n",
    "        \n",
    "        v = get_val(val.strip())\n",
    "        \n",
    "        model_pars[key.strip()] = v\n",
    "\n",
    "model_pars[\"noise\"] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db93cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data parameters\n",
    "with open(mod + \".py\", \"r\") as F:\n",
    "    lines = F.read().split(\"\\n\")\n",
    "\n",
    "data_pars = {}\n",
    "in_pars = False\n",
    "\n",
    "# Parse script\n",
    "for l in lines:\n",
    "    \n",
    "    # Identify model parameter block start\n",
    "    if \"data_pars = \" in l:\n",
    "        in_pars = True\n",
    "    \n",
    "    # Identify model parameter block end\n",
    "    if l.strip() == \")\":\n",
    "        in_pars = False\n",
    "    \n",
    "    if in_pars:\n",
    "        # Get line\n",
    "        if \"(\" in l:\n",
    "            L = l.split(\"(\")[1].split(\"#\")[0]\n",
    "        else:\n",
    "            L = l.strip().split(\"#\")[0]\n",
    "        \n",
    "        if \"=\" in L:\n",
    "        \n",
    "            key, val = L.split(\"=\")\n",
    "        \n",
    "            v = get_val(val.strip())\n",
    "        \n",
    "            data_pars[key.strip()] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e75556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "# Load loss and learning rate\n",
    "all_lrs = np.load(in_dir + \"all_lrs.npy\")\n",
    "all_losses = np.load(in_dir + \"all_losses.npy\")\n",
    "all_val_losses = np.load(in_dir + \"all_val_losses.npy\")\n",
    "\n",
    "mean_losses = np.mean(all_losses, axis=1)\n",
    "mean_val_losses = np.mean(all_val_losses, axis=1)\n",
    "\n",
    "n_chk = all_losses.shape[0]\n",
    "best_chk = np.argmin(mean_val_losses)\n",
    "print(best_chk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd169b5-91e9-4227-8833-0c002b4d7564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTMEnsemble(\n",
       "  (models): ModuleList(\n",
       "    (0): ConvLSTM(\n",
       "      (cell_list): ModuleList(\n",
       "        (0): ConvLSTMCell(\n",
       "          (conv): Conv1d(76, 192, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "        )\n",
       "        (2): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(25,), stride=(1,), padding=(12,))\n",
       "        )\n",
       "        (3): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(35,), stride=(1,), padding=(17,))\n",
       "        )\n",
       "        (4): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(45,), stride=(1,), padding=(22,))\n",
       "        )\n",
       "        (5): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(55,), stride=(1,), padding=(27,))\n",
       "        )\n",
       "      )\n",
       "      (final_conv): Conv1d(64, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (final_act): Sigmoid()\n",
       "    )\n",
       "    (1): ConvLSTM(\n",
       "      (cell_list): ModuleList(\n",
       "        (0): ConvLSTMCell(\n",
       "          (conv): Conv1d(76, 192, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "        )\n",
       "        (2): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(25,), stride=(1,), padding=(12,))\n",
       "        )\n",
       "        (3): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(35,), stride=(1,), padding=(17,))\n",
       "        )\n",
       "        (4): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(45,), stride=(1,), padding=(22,))\n",
       "        )\n",
       "        (5): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(55,), stride=(1,), padding=(27,))\n",
       "        )\n",
       "      )\n",
       "      (final_conv): Conv1d(64, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (final_act): Sigmoid()\n",
       "    )\n",
       "    (2): ConvLSTM(\n",
       "      (cell_list): ModuleList(\n",
       "        (0): ConvLSTMCell(\n",
       "          (conv): Conv1d(76, 192, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "        )\n",
       "        (2): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(25,), stride=(1,), padding=(12,))\n",
       "        )\n",
       "        (3): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(35,), stride=(1,), padding=(17,))\n",
       "        )\n",
       "        (4): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(45,), stride=(1,), padding=(22,))\n",
       "        )\n",
       "        (5): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(55,), stride=(1,), padding=(27,))\n",
       "        )\n",
       "      )\n",
       "      (final_conv): Conv1d(64, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (final_act): Sigmoid()\n",
       "    )\n",
       "    (3): ConvLSTM(\n",
       "      (cell_list): ModuleList(\n",
       "        (0): ConvLSTMCell(\n",
       "          (conv): Conv1d(76, 192, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "        )\n",
       "        (2): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(25,), stride=(1,), padding=(12,))\n",
       "        )\n",
       "        (3): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(35,), stride=(1,), padding=(17,))\n",
       "        )\n",
       "        (4): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(45,), stride=(1,), padding=(22,))\n",
       "        )\n",
       "        (5): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(55,), stride=(1,), padding=(27,))\n",
       "        )\n",
       "      )\n",
       "      (final_conv): Conv1d(64, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (final_act): Sigmoid()\n",
       "    )\n",
       "    (4): ConvLSTM(\n",
       "      (cell_list): ModuleList(\n",
       "        (0): ConvLSTMCell(\n",
       "          (conv): Conv1d(76, 192, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "        )\n",
       "        (2): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(25,), stride=(1,), padding=(12,))\n",
       "        )\n",
       "        (3): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(35,), stride=(1,), padding=(17,))\n",
       "        )\n",
       "        (4): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(45,), stride=(1,), padding=(22,))\n",
       "        )\n",
       "        (5): ConvLSTMCell(\n",
       "          (conv): Conv1d(128, 192, kernel_size=(55,), stride=(1,), padding=(27,))\n",
       "        )\n",
       "      )\n",
       "      (final_conv): Conv1d(64, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (final_act): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global net\n",
    "net = model.ConvLSTMEnsemble(**model_pars)\n",
    "net.eval()\n",
    "# Load best model\n",
    "net.load_state_dict(torch.load(in_dir + f\"checkpoint_{best_chk+1}_network\", map_location=torch.device(\"cpu\")))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90b48ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_topspin_spectrum(zfile, d):\n",
    "    \n",
    "    log = \"\"\n",
    "    \n",
    "    pd = d + \"pdata/1/\"\n",
    "    \n",
    "    fr = pd + \"1r\"\n",
    "    fi = pd + \"1i\"\n",
    "    \n",
    "    wr = None\n",
    "\n",
    "    try:\n",
    "        with zfile.open(fr, \"r\") as F:\n",
    "            data = F.read()\n",
    "            dr = np.frombuffer(data, np.int32).astype(float)\n",
    "\n",
    "        with zfile.open(fi, \"r\") as F:\n",
    "            data = F.read()\n",
    "            di = np.frombuffer(data, np.int32).astype(float)\n",
    "\n",
    "        with zfile.open(f\"{d}acqus\", \"r\") as F:\n",
    "            lines = F.read().decode('utf-8').split(\"\\n\")\n",
    "\n",
    "        for l in lines:\n",
    "            if l.startswith(\"##$MASR=\"):\n",
    "                wr = int(l.split(\"=\")[1].strip())\n",
    "            if l.startswith(\"##$TD=\"):\n",
    "                TD = int(l.split(\"=\")[1].strip())\n",
    "            if l.startswith(\"##$SW_h=\"):\n",
    "                SW = float(l.split(\"=\")[1].strip())\n",
    "\n",
    "        with zfile.open(f\"{pd}procs\", \"r\") as F:\n",
    "            lines = F.read().decode('utf-8').split(\"\\n\")\n",
    "\n",
    "        for l in lines:\n",
    "            if l.startswith(\"##$SI=\"):\n",
    "                n_pts = int(l.split(\"=\")[1].strip())\n",
    "\n",
    "            if l.startswith(\"##$OFFSET=\"):\n",
    "                offset = float(l.split(\"=\")[1].strip())\n",
    "\n",
    "            if l.startswith(\"##$SF=\"):\n",
    "                SF = float(l.split(\"=\")[1].strip())\n",
    "\n",
    "    except:\n",
    "        return None, None, None, None, None, log\n",
    "            \n",
    "    AQ = TD / (2 * SW)\n",
    "\n",
    "    hz = offset * SF - np.arange(n_pts) / (2 * AQ * n_pts / TD)\n",
    "    \n",
    "    ppm = hz / SF\n",
    "\n",
    "    return dr, di, wr, ppm, hz, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ea0512a-60db-4bb4-8cb6-455c5908f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_exp_topspin(zfile, d0, v=False, custom_ws=None, n=1000):\n",
    "    \n",
    "    logs = \"\"\n",
    "    \n",
    "    X = []\n",
    "    ws = []\n",
    "    ppm = None\n",
    "    for i in range(n):\n",
    "        d = f\"{d0}{i+1}/\"\n",
    "        if d in zfile.namelist():\n",
    "            if v > 1:\n",
    "                logs += f\"INFO: loading dataset {d}\\n\"\n",
    "            Xi, _, wr, tmp_ppm, hz, log = load_topspin_spectrum(zfile, d)\n",
    "            if hz is not None:\n",
    "                X.append(Xi)\n",
    "                ws.append(wr)\n",
    "                ppm = tmp_ppm\n",
    "            elif v > 0:\n",
    "                logs += f\"WARNING: dataset {d} could not be loaded!\\n\"\n",
    "            logs += log\n",
    "        \n",
    "    if len(X) == 0:\n",
    "        logs += f\"ERROR: no dataset from {d0} could be loaded!\\n\"\n",
    "        return None, None, None, logs\n",
    "    \n",
    "    if custom_ws is not None:\n",
    "        ws = custom_ws\n",
    "    \n",
    "    sorted_inds = np.argsort(ws)\n",
    "    \n",
    "    sorted_ws = np.array([ws[i] for i in sorted_inds])\n",
    "    \n",
    "    sorted_X = np.array([X[i] for i in sorted_inds])\n",
    "    \n",
    "    return ppm, sorted_ws, sorted_X, logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5573688b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_input(X, ws, x_max=0.25):\n",
    "    \n",
    "    # Normalize spectra\n",
    "    X /= np.sum(X, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    inds = np.argsort(ws)\n",
    "    X_torch = torch.Tensor(X[inds])\n",
    "    X_torch = torch.unsqueeze(X_torch, dim=0)\n",
    "    X_torch = torch.unsqueeze(X_torch, dim=2)\n",
    "    \n",
    "    X_torch /= torch.max(X_torch)\n",
    "    X_torch *= x_max\n",
    "    \n",
    "    if data_pars[\"encode_w\"]:\n",
    "        W = torch.Tensor(ws[inds])\n",
    "        W = torch.unsqueeze(W, dim=0)\n",
    "        W = torch.unsqueeze(W, dim=2)\n",
    "        W = torch.unsqueeze(W, dim=3)\n",
    "        W = W.repeat(1, 1, 1, X_torch.shape[-1])\n",
    "        \n",
    "        if data_pars[\"norm_wr\"]:\n",
    "            W -= data_pars[\"mas_w_range\"][0]\n",
    "            W /= data_pars[\"mas_w_range\"][1] - data_pars[\"mas_w_range\"][0]\n",
    "    \n",
    "    X_torch = torch.cat([X_torch, W], dim=2)\n",
    "    \n",
    "    return X[inds], X_torch, ws[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14371603-37e6-49a6-8444-c3202aad6244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_exp_vs_pred(ppm, X, y_pred, y_std, y_pred_scale=0.5, x_offset=0.1, xl=[20., -5.], c0=[0., 1., 1.], dc = [0., -1., 0.]):\n",
    "    \n",
    "    # Initialize figure\n",
    "    try:\n",
    "        X2 = np.copy(X.numpy())\n",
    "    except:\n",
    "        X2 = np.copy(X)\n",
    "    \n",
    "    X2 /= np.max(X2)\n",
    "    \n",
    "    if len(X2.shape) == 1:\n",
    "        X2 = np.expand_dims(X2, 0)\n",
    "    n = X2.shape[0]\n",
    "    \n",
    "    dy = (n-1) * x_offset\n",
    "    \n",
    "    fig = plt.figure(figsize=(4,3+dy))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    if n == 1:\n",
    "        colors = [[ci + dci for ci, dci in zip(c0, dc)]]\n",
    "        \n",
    "    else:\n",
    "        colors = [[ci + (dci * i / (n-1)) for ci, dci in zip(c0, dc)] for i in range(n)]\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        y_pred2 = y_pred.numpy()\n",
    "        y_std2 = y_std.numpy()\n",
    "    except:\n",
    "        y_pred2 = y_pred\n",
    "        y_std2 = y_std\n",
    "    \n",
    "    factor = np.max(y_pred2) / y_pred_scale\n",
    "    y_pred2 /= factor\n",
    "    y_std2 /= factor\n",
    "    \n",
    "    # Plot inputs\n",
    "    for i, (c, x) in enumerate(zip(colors, X2)):\n",
    "        h1 = ax.plot(ppm, x + i * x_offset, color=c, linewidth=1)\n",
    "    \n",
    "    # Plot predictions\n",
    "    h2 = ax.plot(ppm, y_pred2, \"r\", linewidth=1)\n",
    "    ax.fill_between(ppm, y_pred2 - y_std2, y_pred2 + y_std2, color=\"r\", alpha=0.3)\n",
    "    \n",
    "    # Update axis\n",
    "    ax.set_xlim(xl)\n",
    "    ax.set_ylim(-0.05, 1.05 + ((n-1) * x_offset))\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(\"Chemical shift [ppm]\")\n",
    "    \n",
    "    ax.legend([h1[0], h2[0]], [\"MAS spectra\", \"PIPNet prediction\"])\n",
    "    \n",
    "    # Cleanup layout\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    b = io.BytesIO()\n",
    "    fig.savefig(b, format=\"pdf\")\n",
    "    plt.close()\n",
    "    \n",
    "    return fig, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b1615c9-34c5-4ea2-9eea-e71d8cb52d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file(x):\n",
    "    \n",
    "    if len(x.shape) > 2:\n",
    "        raise ValueError(\"Only up to 2D numpy arrays are handled.\")\n",
    "    \n",
    "    if len(x.shape) == 1:\n",
    "        pp = \",\".join([f\"{a:.8f}\" for a in x])\n",
    "    else:\n",
    "        pp = \"\"\n",
    "        for xi in x:\n",
    "            pp += \",\".join([f\"{a:.8f}\" for a in xi])\n",
    "            pp += \"\\n\"\n",
    "    \n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "196142e6-e981-4e86-a4ff-4edc5e463aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_files(files, names, figs=[], fig_names=[]):\n",
    "    \n",
    "    cur_dt = datetime.datetime.now().strftime(\"%Y_%m_%d-%Hh%Mm%Ss\")\n",
    "    out_name = f\"preds_{cur_dt}.zip\"\n",
    "    \n",
    "    with zp.ZipFile(out_name, mode=\"w\", compression=zp.ZIP_DEFLATED) as z:\n",
    "        for file, name in zip(files, names):\n",
    "            z.writestr(name + \".csv\", file)\n",
    "        \n",
    "        for fig, name in zip(figs, fig_names):\n",
    "            z.writestr(name + \".pdf\", fig.getvalue())\n",
    "    return out_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "000a02ad-8c10-478d-8f0a-e675c517fafc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7879/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7879/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1392f7430>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<fastapi.applications.FastAPI at 0x12d80a880>, 'http://127.0.0.1:7879/', None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_prediction(file_obj, str_ws, w0, w1, dw, x0, x1, scale, verbose):\n",
    "    \n",
    "    if verbose == \"Errors only\":\n",
    "        v = 0\n",
    "    elif verbose == \"Errors and warnings\":\n",
    "        v = 1\n",
    "    else:\n",
    "        v = 2\n",
    "    \n",
    "    log = \"\"\n",
    "    \n",
    "    # Load spectra\n",
    "    zfile = zp.ZipFile(file_obj.name)\n",
    "    basename = zfile.namelist()[0]\n",
    "    \n",
    "    ppm, ws, X, add_log = extract_exp_topspin(zfile, basename, v=v)\n",
    "    log += add_log\n",
    "    \n",
    "    if abs(ppm[1]-ppm[0]) < 0.01 or abs(ppm[1]-ppm[0]) > 0.05 and v > 0:\n",
    "        log += \"WARNING: the spectral resolution should be around 0.01-0.05 ppm\"\n",
    "    \n",
    "    if len(str_ws) > 0:\n",
    "        \n",
    "        try:\n",
    "            ws = np.array([int(w) * 1000 for w in str_ws.split(\",\")])\n",
    "        except:\n",
    "            log += \"ERROR: Could not read the list of MAS rates.\\n\"\n",
    "            log += \"  Valid input should contain only comma-separated integers.\\n\"\n",
    "            log += \"  e.g. 20,30,40,50,60,70,80,90,100\"\n",
    "    \n",
    "    if \"ERROR\" in log:\n",
    "        return log, None, None, None, None\n",
    "    \n",
    "    if v > 1:\n",
    "        log += \"INFO: Available MAS rates (in order of loaded datasets): \"\n",
    "        log += \",\".join(str(w) for w in ws)\n",
    "        log += \"\\n\"\n",
    "    \n",
    "    # Restrict spectral range for performance\n",
    "    i0 = np.where(ppm > x0)[0][-10]\n",
    "    i1 = np.where(ppm < x1)[0][9]\n",
    "    ppm = ppm[i0:i1]\n",
    "    X = X[:, i0:i1]\n",
    "    \n",
    "    # Pre-process spectra\n",
    "    X, X_torch, ws = make_input(X, ws)\n",
    "    sel_ws = np.arange(w0, w1+dw, dw) * 1000\n",
    "    \n",
    "    w_inds = []\n",
    "    for w in sel_ws:\n",
    "        w_inds.append(np.argmin(np.abs(ws - w)))\n",
    "    \n",
    "    if v > 1:\n",
    "        log += \"INFO: Prediction of the following MAS rates: \"\n",
    "        log += \",\".join(str(w) for w in ws[w_inds])\n",
    "        log += \"\\n\"\n",
    "\n",
    "    X_net = X_torch[:, w_inds]\n",
    "    X_net[:, :, 0] /= torch.max(X_net[:, :, 0]) / scale\n",
    "\n",
    "    # Perform prediction\n",
    "    y_pred, y_std, ys = net(X_net)\n",
    "\n",
    "    y_pred = y_pred.detach().numpy()[0]\n",
    "    y_std = y_std.detach().numpy()[0]\n",
    "\n",
    "    ymax = np.max(y_pred)\n",
    "    y_pred /= ymax / 0.5\n",
    "\n",
    "    y_std /= ymax / 0.5\n",
    "    \n",
    "    all_figs = []\n",
    "    fig_names = []\n",
    "    figs = []\n",
    "    for i, (yi_pred, yi_std) in enumerate(zip(y_pred, y_std)):\n",
    "        fig, b = plot_exp_vs_pred(ppm, X[w_inds[model_pars[\"batch_input\"]+i-1]], yi_pred, yi_std, x_offset=0., xl=[x0, x1])\n",
    "        figs.append(fig)\n",
    "        all_figs.append(b)\n",
    "        fig_names.append(f\"Prediction_step_{i+1}\")\n",
    "    fig, b = plot_exp_vs_pred(ppm, X[w_inds], y_pred[-1], y_std[-1], x_offset=0., xl=[x0, x1])\n",
    "    all_figs.append(b)\n",
    "    fig_names.append(f\"Final_prediction\")\n",
    "    \n",
    "    zipped_results = zip_files([make_file(ppm), make_file(y_pred), make_file(y_std)], [\"ppm\", \"pred\", \"err\"], all_figs, fig_names)\n",
    "    \n",
    "    if len(log) == 0:\n",
    "        log = \"INFO: No issue to report!\"\n",
    "    \n",
    "    return log, fig, figs[-1], figs, zipped_results\n",
    "\n",
    "iface = gr.Interface(fn=make_prediction,\n",
    "                     \n",
    "                     inputs=[gr.inputs.File(label=\"ZIP file containing the Topspin dataset\"),\n",
    "                                             gr.inputs.Textbox(lines=3, default=\"\", placeholder=\"List of the MAS rate for each spectrum, in kHz (comma-separated). This overwrites the \"),\n",
    "                                             gr.inputs.Slider(minimum=20, maximum=100, step=1, default=30, label=\"Starting MAS rate [kHz]\"),\n",
    "                                             gr.inputs.Slider(minimum=20, maximum=100, step=1, default=80, label=\"Final MAS rate [kHz]\"),\n",
    "                                             gr.inputs.Slider(minimum=1, maximum=10, step=1, default=2, label=\"MAS rate step [kHz]\"),\n",
    "                                             gr.inputs.Number(default=20, label=\"Left chemical shift limit [ppm]\"),\n",
    "                                             gr.inputs.Number(default=-5, label=\"Right chemical shift limit [ppm]\"),\n",
    "                                             gr.inputs.Number(default=0.2, label=\"MAS spectra scale (default: 0.2)\"),\n",
    "                                             gr.inputs.Radio(choices=[\"Errors only\", \"Errors and warnings\", \"Errors, warnings and info\"], default=\"Errors and warnings\", label=\"Verbosity level\")],\n",
    "                     \n",
    "                     outputs=[gr.outputs.Textbox(label=\"INFO\"),\n",
    "                              gr.outputs.Image(\"plot\", label=\"Final prediction with all spectra used\"),\n",
    "                              gr.outputs.Image(\"plot\", label=\"Final prediction with final spectrum used\"),\n",
    "                              gr.outputs.Carousel(\"plot\", label=\"Evolution of the prediction with additional spectra\"),\n",
    "                              gr.outputs.File(label=\"Downloadable predictions\")],\n",
    "                     title=\"PIPNet: Prediction of isotropic 1H NMR spectra using deep learning\",\n",
    "                     theme=\"dark\")\n",
    "#iface.launch(share=True)\n",
    "iface.launch(enable_queue=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7f606c-8314-4824-bdef-3a6c17708a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
